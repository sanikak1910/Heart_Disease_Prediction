# -*- coding: utf-8 -*-
"""Heart_Disease_Prediction_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14p_XyCQp28VLsxUlRM159u9l8fQW6jv3

## <font size=5> <strong>Heart Disease Prediction

## I. Importing essential libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
# %matplotlib inline
import joblib
import os
print(os.listdir())
import warnings
warnings.filterwarnings('ignore')

"""## II. Importing and understanding our dataset"""

dataset = pd.read_csv("archive/heart_disease_uci.csv")

dataset.shape

dataset.head(5)

dataset.sample(5)

"""#### Description of Dataset"""

dataset.describe()

dataset.info()

info = ["id(Unique for each patient)","age","1: male, 0: female", "dataset from Cleveland, Hungary, VA Long Beach, Switzerland",
        "chest pain type, 1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic","resting blood pressure",
        " serum cholestoral in mg/dl","fasting blood sugar > 120 mg/dl","resting electrocardiographic results (values 0,1,2)",
        " maximum heart rate achieved","exercise induced angina","oldpeak = ST depression induced by exercise relative to rest",
        "the slope of the peak exercise ST segment","number of major vessels (0-3) colored by flourosopy",
        "thal: 3 = normal; 6 = fixed defect; 7 = reversable defect",
        "target value:  0: No Heart Disease 1: Mild Heart Disease 2: Moderate Heart Disease 3: Severe Heart Disease,4: Critical Heart Disease"]

for i in range(len(info)):
    print(dataset.columns[i]+":\t\t\t"+info[i])

"""#### Analysing the 'target' variable"""

dataset["num"].describe()

dataset["num"].unique()

"""Univariate Analysis

Age Column
"""

plt.figure(figsize=(10,6))
sns.histplot(dataset.age, color="purple",kde=True, alpha=0.7)
plt.legend()
plt.title("Age Distribution")
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.grid(axis='y')
plt.show()

#plotting mean, median and mode of the age column
plt.figure(figsize=(10,6))
sns.histplot(dataset['age'], bins=20, color="blue", kde=True, alpha=0.7)
plt.axvline(dataset['age'].mean(), color="red", linestyle="dashed", linewidth=2, label="Mean")
plt.axvline(dataset['age'].median(), color="green", linestyle="dashed", linewidth=2, label="Median")
plt.axvline(dataset['age'].mode()[0], color="yellow", linestyle="dashed", linewidth=2, label="Mode")
plt.title("Age Distribution with Mean, median and mode")
plt.xlabel('Age')
plt.ylabel("Frequency")
plt.legend()
plt.grid(axis='y')


print(f"Mean of age column: {round(dataset['age'].mean(),2)}")
print(f"Median of age column: {dataset['age'].median()}")
print(f"Mode of age column: {dataset['age'].mode()[0]}")
plt.show()

"""Insights:
1. Minimum age to have a heart disease is 28 years.
2. Maximum people get heart disease at age 55-58.
"""

sex_count = dataset['sex'].value_counts()
sex_percentage = round(sex_count*100/ len(dataset),2)
print(pd.DataFrame({'Count': sex_count, 'Percentage': sex_percentage}))

plt.figure(figsize=(10,6))
sns.histplot(data= dataset, x='age', hue='sex', kde=False, stat='count', palette='Set1', element='step', multiple='layer', alpha=0.8)

plt.title('Age Distribution by Sex')
plt.xlabel('Age')
plt.ylabel('Count')
plt.legend(title='Sex')
plt.tight_layout()
plt.show()

"""Insights:
1. Most of the males and females get heart disease around 54-55 age.
2. Males have higher chances of getting a heart disease.

Dataset column
"""

print(dataset['dataset'].unique())

dataset['dataset'].value_counts()

plt.figure(figsize=(10,6))
sns.countplot(x= dataset['dataset'], palette='Set2')
plt.title('Dataset Distribution')
plt.xlabel('Dataset')
plt.ylabel('Count')
plt.show()

sns.countplot(data=dataset, x='dataset', hue='sex', palette='Set1')
plt.title('Dataset Count by Sex')
plt.xlabel('Dataset')
plt.ylabel('Count')

plt.show()

"""*   **Cleveland** : Males=207, Females=97
*   **Hungary**: Males=212, Females=81
*   **Switzerland**: Males=113,Females=10
*   **VA Long Beach**: Males=194,Females=6

1. Hungary has the highest number of males and Switzerland has the least amount of males to get a heart disease.

2. Cleaveland has the highest number of males and VA Long Beach has the least amount of males to get a heart disease.
"""

sns.histplot(data=dataset, x='age', hue='dataset', palette='Set1', multiple='layer', element='step', alpha=0.75, stat='count')
plt.title('Dataset Count by Age')
plt.xlabel('Dataset')
plt.ylabel('Count')

plt.show()

#cp column
print(dataset['cp'].unique())
print(dataset['cp'].value_counts())

plt.figure(figsize=(10, 6))

sns.histplot(data=dataset, x='age', hue='cp', multiple='layer',
             element='step', palette='Set1', alpha=0.75, stat='count')

plt.title('Distribution of Age for Different Chest Pain Types')
plt.xlabel('Age')
plt.ylabel('Count')
plt.legend(title='Chest Pain Type')
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))

sns.countplot(data=dataset, x='cp', hue='sex', palette='Set1', alpha=0.75)

plt.title('Distribution of Chest Pain Types by Sex')
plt.xlabel('Chest Pain Type')
plt.ylabel('Count')
plt.legend(title='Sex')
plt.tight_layout()
plt.show()

"""1. Asymptomatic is the most common chest pain type. It is more in males with over 400 male cases.
2. Typical Angina is rare, especially among females.
3. Non-anginal and Atypical Angina is somewhat evenly distributed.  
"""

# print(dataset.corr()["num"].abs().sort_values(ascending=False))

"""## Exploratory Data Analysis (EDA)

### First, analysing the target variable:
"""

num_labels = {
    0: 'No Heart Disease',
    1: 'Mild Heart Disease',
    2: 'Moderate Heart Disease',
    3: 'Severe Heart Disease',
    4: 'Critical Heart Disease'
}
mapped = dataset['num'].map(num_labels)
num_counts = mapped.value_counts().reset_index()
num_counts.columns = ['Heart Disease Level', 'Count']

# Colors for bars
colors = ['#2a9d8f', '#f4a261', '#e76f51', '#264653', '#8ab17d']

# Plot
plt.figure(figsize=(10, 6))
ax = sns.barplot(
    x='Heart Disease Level',
    y='Count',
    data=num_counts,
    palette=colors
)

# Add count labels on top of bars
for container in ax.containers:
    ax.bar_label(container, label_type='edge', fontsize=11, padding=3)

# Final touches
plt.title('Distribution of Heart Disease Severity', fontsize=16)
plt.xlabel('Heart Disease Level', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.xticks(rotation=15)
plt.grid(axis='y', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

df= dataset.copy()
df['num'] = df['num'].apply(lambda x: 1 if x>0 else 0)

#Presence and Absence of Heart Disease
disease_count = df['num'].value_counts()

print("Percentage of patience without heart problems: "+str(round(disease_count[0]*100/len(df),2)))
print("Percentage of patience with heart problems: "+str(round(disease_count[1]*100/len(df),2)))

#Alternatively,
# print("Percentage of patience with heart problems: "+str(y.where(y==1).count()*100/303))
# print("Percentage of patience with heart problems: "+str(y.where(y==0).count()*100/303))

# #Or,
# countNoDisease = len(df[df.target == 0])
# countHaveDisease = len(df[df.target == 1])

plt.figure(figsize=(6, 6))
plt.pie(disease_count, labels=disease_count.index, autopct='%1.1f%%', startangle=90, colors=['green', 'red'])
plt.title('Heart Disease Distribution (1 = Presence of heart disease, 0 = Absence of heart disease)')
plt.show()

def heart_disease_corr(type, col_name):
    # count occurrences using .size()
    _disease_counts = df.groupby([type, 'num']).size().reset_index(name='Count')

    # rename columns for clarity
    _disease_counts.columns = [col_name, 'Heart Disease', 'Count']

    # plot a grouped bar chart
    plt.figure(figsize=(8, 6))
    sns.barplot(data=_disease_counts, x=col_name, y='Count', hue='Heart Disease', palette=['green', 'red'])

    plt.title(f'Distribution of {col_name} and Heart Disease')
    plt.xlabel(col_name)
    plt.ylabel('Count')
    plt.legend(title='Presence of heart disease: green = no, red = yes')
    plt.tight_layout()
    plt.show()

heart_disease_corr('sex', 'Sex')

print(dataset['trestbps'].describe())

#Missing values in trestbps column
missing_trestbps = dataset['trestbps'].isnull().sum()
print("Missing Values in trestbps: ", missing_trestbps)
print(f"Percentage of missing values: {round(missing_trestbps*100/len(dataset),2)}")

# Impute the missing values in the trestbps column using iterative imputer
imputer_1 = IterativeImputer(max_iter=10, random_state=42)
dataset['trestbps'] = imputer_1.fit_transform(dataset[['trestbps']])
# Check for missing values in the trestbps column again
missing_percentage = (dataset['trestbps'].isnull().sum() / len(dataset)) * 100
print(f"Number of missing values in the 'trestbps' column after imputation: {dataset['trestbps'].isnull().sum()} ({missing_percentage:.2f}%)")

#Missing Values in columns
missing_values = df.isnull().sum()
missing_values = missing_values[missing_values > 0]
missing_percentage = (missing_values / len(df)) * 100
print("Missing Values in the dataset:")
print(pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage}))

# Impute missing values of numerical columns using iterative imputer
imputer_2 = IterativeImputer(max_iter=10, random_state=42)

# Select only numeric columns for imputation
numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
df[numeric_columns] = imputer_2.fit_transform(df[numeric_columns])

# Check for missing values in the dataset again
missing_values = df.isnull().sum()
missing_values = missing_values[missing_values > 0]
missing_percentage = (missing_values / len(df)) * 100
missing_values = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})
# Display the missing values
print("Missing values in the dataset after imputation:")
print(missing_values)

categorical_cols = ['fbs', 'restecg', 'exang', 'slope','thal']
for col in categorical_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

missing_values = df.isnull().sum()
missing_values = missing_values[missing_values > 0]
missing_percentage = (missing_values / len(df)) * 100
missing_values = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})
# Display the missing values
print("Missing values in the dataset after imputation:")
print(missing_values)

"""Dealing with Outliers

"""

# creat box plots for all the numeric columns using for loop and subplot
fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))
axes = axes.flatten()
numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
for i, col in enumerate(numeric_columns):
    sns.boxplot(data=df, x=col, ax=axes[i])
    axes[i].set_title(f'Box plot of {col}')
    axes[i].grid(axis='y', alpha=0.75)
plt.tight_layout()
plt.show()

# from plotly.subplots import make_subplots
# import plotly.graph_objects as go
# import plotly.express as px

# Create box plots for all numeric columns using Plotly
# Create individual box plots for each numeric column using Plotly
# Create individual box plots for each numeric column using Plotly subplots

# Create a subplot figure
# fig = make_subplots(rows=len(numeric_columns), cols=1, shared_xaxes=True, vertical_spacing=0.02)

# # Add a box plot for each numeric column
# for i, col in enumerate(numeric_columns):
#     fig.add_trace(
#         px.box(df, y=col, points="all").data[0],
#         row=i + 1,
#         col=1
#     )

# # Update layout
# fig.update_layout(
#     height=300 * len(numeric_columns),  # Adjust height based on the number of subplots
#     title_text="Box Plots of Numeric Columns",
#     showlegend=False
# )

# fig.show()

df[df['trestbps']==0]
df = df[df['trestbps']!=0]

"""## IV. Train Test split"""

df

df_train = df.copy()

df_train

df_train.drop(['id','dataset'],axis=1)

categorical_columns = df_train.select_dtypes(include=['object','bool']).columns.tolist()
categorical_columns

numeric_features  = df_train.select_dtypes(include=['int64','float64']).columns.tolist()
numeric_features

df_train

# Unique Values
# df1['sex'].unique()
for col in categorical_columns:
    print(f'{col}:{df_train[col].unique()}')

label_encoder = preprocessing.LabelEncoder()
for col in categorical_columns:
    df_train[col]=label_encoder.fit_transform(df_train[col])
    print(f'{col}:{df_train[col].unique()}')

df_train

df_train = df_train.drop(['id','dataset'],axis=1)

df_train

for col in df_train:
  df_train[col]= df_train[col].astype(int)

df_train

predictors = df_train.drop('num',axis=1)
target = df_train['num']

predictors

target

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test = train_test_split(predictors,target,test_size=0.20,random_state=0)

X_train.head(5)

X_train.shape

X_test.head(5)

X_test.shape

Y_train.head(5)

Y_train.shape

Y_test.shape

"""## V. Model Fitting"""

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay

"""### Logistic Regression"""

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()

lr.fit(X_train,Y_train)

Y_pred_lr = lr.predict(X_test)

Y_pred_lr.shape

cm = confusion_matrix(Y_test, Y_pred_lr)
cm

plt.figure(figsize=(4, 3))
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot()
plt.show()

print("Classification Report:\n", classification_report(Y_test, Y_pred_lr))

score_lr = round(accuracy_score(Y_pred_lr,Y_test)*100,2)

print("The accuracy score achieved using Logistic Regression is: "+str(score_lr)+" %")

"""### Naive Bayes"""

from sklearn.naive_bayes import GaussianNB

nb = GaussianNB()

nb.fit(X_train,Y_train)

Y_pred_nb = nb.predict(X_test)

Y_pred_nb.shape

cm = confusion_matrix(Y_test, Y_pred_nb)
cm

plt.figure(figsize=(4, 3))
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot()
plt.show()

print("Classification Report:\n", classification_report(Y_test, Y_pred_nb))

score_nb = round(accuracy_score(Y_pred_nb,Y_test)*100,2)

print("The accuracy score achieved using Naive Bayes is: "+str(score_nb)+" %")

"""### SVM"""

from sklearn import svm

sv = svm.SVC(kernel='linear')

sv.fit(X_train, Y_train)

Y_pred_svm = sv.predict(X_test)

Y_pred_svm.shape

cm = confusion_matrix(Y_test, Y_pred_svm)
cm

plt.figure(figsize=(4, 3))
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot()
plt.show()

print("Classification Report:\n", classification_report(Y_test, Y_pred_svm))

score_svm = round(accuracy_score(Y_pred_svm,Y_test)*100,2)

print("The accuracy score achieved using Linear SVM is: "+str(score_svm)+" %")

"""### K Nearest Neighbors"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=7)
knn.fit(X_train,Y_train)
Y_pred_knn=knn.predict(X_test)

Y_pred_knn.shape

cm = confusion_matrix(Y_test, Y_pred_knn)
cm

plt.figure(figsize=(4, 3))
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot()
plt.show()

print("Classification Report:\n", classification_report(Y_test, Y_pred_knn))

score_knn = round(accuracy_score(Y_pred_knn,Y_test)*100,2)

print("The accuracy score achieved using KNN is: "+str(score_knn)+" %")

"""### Decision Tree"""

from sklearn.tree import DecisionTreeClassifier

max_accuracy = 0


for x in range(200):
    dt = DecisionTreeClassifier(random_state=x)
    dt.fit(X_train,Y_train)
    Y_pred_dt = dt.predict(X_test)
    current_accuracy = round(accuracy_score(Y_pred_dt,Y_test)*100,2)
    if(current_accuracy>max_accuracy):
        max_accuracy = current_accuracy
        best_x = x

#print(max_accuracy)
#print(best_x)


dt = DecisionTreeClassifier(random_state=best_x)
dt.fit(X_train,Y_train)
Y_pred_dt = dt.predict(X_test)

print(Y_pred_dt.shape)

cm = confusion_matrix(Y_test, Y_pred_dt)
cm

plt.figure(figsize=(4, 3))
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot()
plt.show()

print("Classification Report:\n", classification_report(Y_test, Y_pred_dt))

score_dt = round(accuracy_score(Y_pred_dt,Y_test)*100,2)

print("The accuracy score achieved using Decision Tree is: "+str(score_dt)+" %")

"""### Random Forest"""

from sklearn.ensemble import RandomForestClassifier

max_accuracy = 0


for x in range(2000):
    rf = RandomForestClassifier(random_state=x)
    rf.fit(X_train,Y_train)
    Y_pred_rf = rf.predict(X_test)
    current_accuracy = round(accuracy_score(Y_pred_rf,Y_test)*100,2)
    if(current_accuracy>max_accuracy):
        max_accuracy = current_accuracy
        best_x = x

#print(max_accuracy)
#print(best_x)

rf = RandomForestClassifier(random_state=best_x)
rf.fit(X_train,Y_train)
Y_pred_rf = rf.predict(X_test)

Y_pred_rf.shape

cm = confusion_matrix(Y_test, Y_pred_rf)
cm

plt.figure(figsize=(4, 3))
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot()
plt.show()

print("Classification Report:\n", classification_report(Y_test, Y_pred_rf))

score_rf = round(accuracy_score(Y_pred_rf,Y_test)*100,2)

print("The accuracy score achieved using Decision Tree is: "+str(score_rf)+" %")

"""### Neural Network"""

# from keras.models import Sequential
# from keras.layers import Dense

# model = Sequential()
# model.add(Dense(11,activation='relu',input_dim=13))
# model.add(Dense(1,activation='sigmoid'))

# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

# model.fit(X_train,Y_train,epochs=300)

# Y_pred_nn = model.predict(X_test)

# Y_pred_nn.shape

# rounded = [round(x[0]) for x in Y_pred_nn]

# Y_pred_nn = rounded

# cm = confusion_matrix(Y_test, Y_pred_nn)
# cm

# plt.figure(figsize=(4, 3))
# disp = ConfusionMatrixDisplay(confusion_matrix = cm)
# disp.plot()
# plt.show()

# print("Classification Report:\n", classification_report(Y_test, Y_pred_nn))

# score_nn = round(accuracy_score(Y_pred_nn,Y_test)*100,2)

# print("The accuracy score achieved using Neural Network is: "+str(score_nn)+" %")

"""## VI. Output final score"""

scores = [score_lr,score_nb,score_svm,score_knn,score_dt,score_rf]
algorithms = ["Logistic Regression","Naive Bayes","Support Vector Machine","K-Nearest Neighbors","Decision Tree","Random Forest"]

for i in range(len(algorithms)):
    print("The accuracy score achieved using "+algorithms[i]+" is: "+str(scores[i])+" %")

sns.set(rc={'figure.figsize':(10,6)})
plt.xlabel("Algorithms")
plt.ylabel("Accuracy score")
plt.xticks(fontsize=8)
plt.yticks(fontsize=8)
plt.title("Accuracy of different Algorithms")
plt.bar(algorithms, scores,width=0.5)
plt.show()

"""### **Random Forest** has good result as compared to other algorithms
###**Accurcy: 90.22%**
"""

joblib.dump(rf, 'heart_disease_model.pkl')
print("Model saved as heart_disease_model.pkl")